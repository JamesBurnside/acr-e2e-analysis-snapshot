{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean raw data \n",
    "\n",
    "This notebook reads data from [../data/raw](../data/raw), fixes up known issues and then writes the cleaned data to [../data/cleaned](../data/cleaned).\n",
    "\n",
    "See cells below for the various data fixes applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-18T17:48:46.878646Z",
     "iopub.status.busy": "2022-11-18T17:48:46.878646Z",
     "iopub.status.idle": "2022-11-18T17:48:48.390565Z",
     "shell.execute_reply": "2022-11-18T17:48:48.390565Z"
    }
   },
   "outputs": [],
   "source": [
    "# All imports live here.\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-18T17:48:48.390565Z",
     "iopub.status.busy": "2022-11-18T17:48:48.390565Z",
     "iopub.status.idle": "2022-11-18T17:50:33.863519Z",
     "shell.execute_reply": "2022-11-18T17:50:33.863519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tests with 1138050 rows. Columns:\n",
      "meta_id                                  int64\n",
      "workflow_id                              int64\n",
      "workflow_run_number                      int64\n",
      "workflow_run_attempt                     int64\n",
      "workflow_created_at        datetime64[ns, UTC]\n",
      "workflow_event                          object\n",
      "workflow_head_branch                    object\n",
      "commit_sha                              object\n",
      "build_flavor                            object\n",
      "composite                               object\n",
      "pw_suite_title                          object\n",
      "pw_spec_title                           object\n",
      "pw_test_project_name                    object\n",
      "pw_test_expected_status                 object\n",
      "pw_test_status                          object\n",
      "pw_result_status                        object\n",
      "pw_result_duration                       int64\n",
      "pw_result_retry                          int64\n",
      "dtype: object\n",
      "Loaded jobs with 745999 rows. Columns:\n",
      "workflow_id                           int64\n",
      "workflow_run_attempt                  int64\n",
      "job_status                           object\n",
      "job_conclusion                       object\n",
      "job_started_at          datetime64[ns, UTC]\n",
      "job_completed_at        datetime64[ns, UTC]\n",
      "job_name                             object\n",
      "step_name                            object\n",
      "step_status                          object\n",
      "step_conclusion                      object\n",
      "step_started_at                      object\n",
      "step_completed_at                    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load raw data\n",
    "with open('../data/raw/playwright.json') as f:\n",
    "    tests = pd.read_json(f)\n",
    "print('Loaded tests with %d rows. Columns:' % (tests.shape[0],))\n",
    "print(tests.dtypes)\n",
    "\n",
    "with open('../data/raw/jobs.json') as f:\n",
    "    jobs = pd.read_json(f)\n",
    "print('Loaded jobs with %d rows. Columns:' % (jobs.shape[0],))\n",
    "print(jobs.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remap project names\n",
    "\n",
    "Projects were renamed by https://github.com/Azure/communication-ui-library/pull/2162\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-18T17:50:33.863519Z",
     "iopub.status.busy": "2022-11-18T17:50:33.863519Z",
     "iopub.status.idle": "2022-11-18T17:50:45.790914Z",
     "shell.execute_reply": "2022-11-18T17:50:45.790914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data had 6 unique projects\n",
      "Cleaned data has 3 unique projects\n"
     ]
    }
   ],
   "source": [
    "# Rename projects\n",
    "PROJECT_NAMES = {\n",
    "    'Desktop Chrome': 'desktop-chrome',\n",
    "    'Mobile Android Portrait': 'mobile-android-portrait',\n",
    "    'Mobile Android Landscape': 'mobile-android-landscape',\n",
    "}\n",
    "\n",
    "print('Raw data had {} unique projects'.format(len(tests['pw_test_project_name'].unique())))\n",
    "\n",
    "def _project_name(row):\n",
    "    n = row['pw_test_project_name']\n",
    "    return PROJECT_NAMES.get(n, n)\n",
    "\n",
    "tests['pw_test_project_name'] = tests.apply(_project_name, axis=1)\n",
    "print('Cleaned data has {} unique projects'.format(len(tests['pw_test_project_name'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented columns\n",
    "\n",
    "Add derived columns to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-18T17:50:45.796023Z",
     "iopub.status.busy": "2022-11-18T17:50:45.796023Z",
     "iopub.status.idle": "2022-11-18T17:50:46.468773Z",
     "shell.execute_reply": "2022-11-18T17:50:46.468773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data with common derived columns:\n",
      "meta_id                                     int64\n",
      "workflow_id                                 int64\n",
      "workflow_run_number                         int64\n",
      "workflow_run_attempt                        int64\n",
      "workflow_created_at           datetime64[ns, UTC]\n",
      "workflow_event                             object\n",
      "workflow_head_branch                       object\n",
      "commit_sha                                 object\n",
      "build_flavor                               object\n",
      "composite                                  object\n",
      "pw_suite_title                             object\n",
      "pw_spec_title                              object\n",
      "pw_test_project_name                       object\n",
      "pw_test_expected_status                    object\n",
      "pw_test_status                             object\n",
      "pw_result_status                           object\n",
      "pw_result_duration                          int64\n",
      "pw_result_retry                             int64\n",
      "workflow_created_date         datetime64[ns, UTC]\n",
      "test_uid                                   object\n",
      "pw_result_duration_seconds                float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Augmented columns for tests\n",
    "tests['workflow_created_date'] = tests['workflow_created_at'].dt.normalize()\n",
    "tests['test_uid'] = tests['composite'].astype(str) + '/' + tests['pw_suite_title'].astype(str) + '/' + tests['pw_spec_title'].astype(str)\n",
    "tests['pw_result_duration_seconds'] = tests['pw_result_duration'] / 1000\n",
    "\n",
    "print('Augmented data with common derived columns:')\n",
    "print(tests.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-18T17:50:46.468773Z",
     "iopub.status.busy": "2022-11-18T17:50:46.468773Z",
     "iopub.status.idle": "2022-11-18T17:50:54.436135Z",
     "shell.execute_reply": "2022-11-18T17:50:54.436135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data with common derived columns:\n",
      "workflow_id                           int64\n",
      "workflow_run_attempt                  int64\n",
      "job_status                           object\n",
      "job_conclusion                       object\n",
      "job_started_at          datetime64[ns, UTC]\n",
      "job_completed_at        datetime64[ns, UTC]\n",
      "job_name                             object\n",
      "step_name                            object\n",
      "step_status                          object\n",
      "step_conclusion                      object\n",
      "step_started_at                      object\n",
      "step_completed_at                    object\n",
      "job_started_date        datetime64[ns, UTC]\n",
      "job_duration_minutes                float64\n",
      "workflow_attempt_uid                 object\n",
      "e2e-composite                        object\n",
      "e2e-flavor                           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Augmented columns for jobs\n",
    "jobs['job_started_date'] = jobs['job_started_at'].dt.normalize()\n",
    "jobs['job_duration_minutes'] = (jobs['job_completed_at'] - jobs['job_started_at']).apply(lambda x: x.total_seconds() / 60.0)\n",
    "\n",
    "jobs['workflow_attempt_uid'] = jobs['workflow_id'].astype(str) + '_' + jobs['workflow_run_attempt'].astype(str)\n",
    "\n",
    "e2e_dimensions = {\n",
    "    'Call Composite automation test (stable)': ('call', 'stable'),\n",
    "    'Call Composite automation test (beta)': ('call', 'beta'),\n",
    "    'Call With Chat Composite automation test (stable)': ('callWithChat', 'stable'),\n",
    "    'Call With Chat Composite automation test (beta)': ('callWithChat', 'beta'),\n",
    "    'Chat Composite automation test (stable)': ('chat', 'stable'),\n",
    "    'Chat Composite automation test (beta)': ('chat', 'beta'),\n",
    "}\n",
    "jobs['e2e-composite'] = jobs['job_name'].map(lambda j: e2e_dimensions.get(j, (None, None))[0])\n",
    "jobs['e2e-flavor'] = jobs['job_name'].map(lambda j: e2e_dimensions.get(j, (None, None))[1])\n",
    "\n",
    "print('Augmented data with common derived columns:')\n",
    "print(jobs.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-18T17:50:54.436135Z",
     "iopub.status.busy": "2022-11-18T17:50:54.436135Z",
     "iopub.status.idle": "2022-11-18T17:51:11.844282Z",
     "shell.execute_reply": "2022-11-18T17:51:11.844282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tests with 1138050 rows. Columns:\n",
      "meta_id                                     int64\n",
      "workflow_id                                 int64\n",
      "workflow_run_number                         int64\n",
      "workflow_run_attempt                        int64\n",
      "workflow_created_at           datetime64[ns, UTC]\n",
      "workflow_event                             object\n",
      "workflow_head_branch                       object\n",
      "commit_sha                                 object\n",
      "build_flavor                               object\n",
      "composite                                  object\n",
      "pw_suite_title                             object\n",
      "pw_spec_title                              object\n",
      "pw_test_project_name                       object\n",
      "pw_test_expected_status                    object\n",
      "pw_test_status                             object\n",
      "pw_result_status                           object\n",
      "pw_result_duration                          int64\n",
      "pw_result_retry                             int64\n",
      "workflow_created_date         datetime64[ns, UTC]\n",
      "test_uid                                   object\n",
      "pw_result_duration_seconds                float64\n",
      "dtype: object\n",
      "Writing jobs with 745999 rows. Columns:\n",
      "workflow_id                           int64\n",
      "workflow_run_attempt                  int64\n",
      "job_status                           object\n",
      "job_conclusion                       object\n",
      "job_started_at          datetime64[ns, UTC]\n",
      "job_completed_at        datetime64[ns, UTC]\n",
      "job_name                             object\n",
      "step_name                            object\n",
      "step_status                          object\n",
      "step_conclusion                      object\n",
      "step_started_at                      object\n",
      "step_completed_at                    object\n",
      "job_started_date        datetime64[ns, UTC]\n",
      "job_duration_minutes                float64\n",
      "workflow_attempt_uid                 object\n",
      "e2e-composite                        object\n",
      "e2e-flavor                           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('Writing tests with %d rows. Columns:' % (tests.shape[0],))\n",
    "print(tests.dtypes)\n",
    "with open('../data/cleaned/playwright.json', 'w') as f:    \n",
    "    tests.to_json(f, indent=1, date_format='iso')\n",
    "\n",
    "print('Writing jobs with %d rows. Columns:' % (jobs.shape[0],))\n",
    "print(jobs.dtypes)\n",
    "with open('../data/cleaned/jobs.json', 'w') as f:\n",
    "    jobs.to_json(f, indent=1, date_format='iso')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('e2eanalysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c3b05de2005fd981399e64c7fa718f103e153aa6eb6a36e3fed7a3ca3494229e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
